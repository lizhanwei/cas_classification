{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv_file='./data/test/test.csv'\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import torch\n",
    "from model.data_loader import DataLoader\n",
    "\n",
    "json_path='./experiments/esm_650M/params.json'\n",
    "params = utils.Params(json_path)\n",
    "params.cuda = torch.cuda.is_available()\n",
    "data_loader = DataLoader('test', params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 396\n",
      "Processing batch 2 of 396\n",
      "Processing batch 3 of 396\n",
      "Processing batch 4 of 396\n",
      "Processing batch 5 of 396\n",
      "Processing batch 6 of 396\n",
      "Processing batch 7 of 396\n",
      "Processing batch 8 of 396\n",
      "Processing batch 9 of 396\n",
      "Processing batch 10 of 396\n",
      "Processing batch 11 of 396\n",
      "Processing batch 12 of 396\n",
      "Processing batch 13 of 396\n",
      "Processing batch 14 of 396\n",
      "Processing batch 15 of 396\n",
      "Processing batch 16 of 396\n",
      "Processing batch 17 of 396\n",
      "Processing batch 18 of 396\n",
      "Processing batch 19 of 396\n",
      "Processing batch 20 of 396\n",
      "Processing batch 21 of 396\n",
      "Processing batch 22 of 396\n",
      "Processing batch 23 of 396\n",
      "Processing batch 24 of 396\n",
      "Processing batch 25 of 396\n",
      "Processing batch 26 of 396\n",
      "Processing batch 27 of 396\n",
      "Processing batch 28 of 396\n",
      "Processing batch 29 of 396\n",
      "Processing batch 30 of 396\n",
      "Processing batch 31 of 396\n",
      "Processing batch 32 of 396\n",
      "Processing batch 33 of 396\n",
      "Processing batch 34 of 396\n",
      "Processing batch 35 of 396\n",
      "Processing batch 36 of 396\n",
      "Processing batch 37 of 396\n",
      "Processing batch 38 of 396\n",
      "Processing batch 39 of 396\n",
      "Processing batch 40 of 396\n",
      "Processing batch 41 of 396\n",
      "Processing batch 42 of 396\n",
      "Processing batch 43 of 396\n",
      "Processing batch 44 of 396\n",
      "Processing batch 45 of 396\n",
      "Processing batch 46 of 396\n",
      "Processing batch 47 of 396\n",
      "Processing batch 48 of 396\n",
      "Processing batch 49 of 396\n",
      "Processing batch 50 of 396\n",
      "Processing batch 51 of 396\n",
      "Processing batch 52 of 396\n",
      "Processing batch 53 of 396\n",
      "Processing batch 54 of 396\n",
      "Processing batch 55 of 396\n",
      "Processing batch 56 of 396\n",
      "Processing batch 57 of 396\n",
      "Processing batch 58 of 396\n",
      "Processing batch 59 of 396\n",
      "Processing batch 60 of 396\n",
      "Processing batch 61 of 396\n",
      "Processing batch 62 of 396\n",
      "Processing batch 63 of 396\n",
      "Processing batch 64 of 396\n",
      "Processing batch 65 of 396\n",
      "Processing batch 66 of 396\n",
      "Processing batch 67 of 396\n",
      "Processing batch 68 of 396\n",
      "Processing batch 69 of 396\n",
      "Processing batch 70 of 396\n",
      "Processing batch 71 of 396\n",
      "Processing batch 72 of 396\n",
      "Processing batch 73 of 396\n",
      "Processing batch 74 of 396\n",
      "Processing batch 75 of 396\n",
      "Processing batch 76 of 396\n",
      "Processing batch 77 of 396\n",
      "Processing batch 78 of 396\n",
      "Processing batch 79 of 396\n",
      "Processing batch 80 of 396\n",
      "Processing batch 81 of 396\n",
      "Processing batch 82 of 396\n",
      "Processing batch 83 of 396\n",
      "Processing batch 84 of 396\n",
      "Processing batch 85 of 396\n",
      "Processing batch 86 of 396\n",
      "Processing batch 87 of 396\n",
      "Processing batch 88 of 396\n",
      "Processing batch 89 of 396\n",
      "Processing batch 90 of 396\n",
      "Processing batch 91 of 396\n",
      "Processing batch 92 of 396\n",
      "Processing batch 93 of 396\n",
      "Processing batch 94 of 396\n",
      "Processing batch 95 of 396\n",
      "Processing batch 96 of 396\n",
      "Processing batch 97 of 396\n",
      "Processing batch 98 of 396\n",
      "Processing batch 99 of 396\n",
      "Processing batch 100 of 396\n",
      "Processing batch 101 of 396\n",
      "Processing batch 102 of 396\n",
      "Processing batch 103 of 396\n",
      "Processing batch 104 of 396\n",
      "Processing batch 105 of 396\n",
      "Processing batch 106 of 396\n",
      "Processing batch 107 of 396\n",
      "Processing batch 108 of 396\n",
      "Processing batch 109 of 396\n",
      "Processing batch 110 of 396\n",
      "Processing batch 111 of 396\n",
      "Processing batch 112 of 396\n",
      "Processing batch 113 of 396\n",
      "Processing batch 114 of 396\n",
      "Processing batch 115 of 396\n",
      "Processing batch 116 of 396\n",
      "Processing batch 117 of 396\n",
      "Processing batch 118 of 396\n",
      "Processing batch 119 of 396\n",
      "Processing batch 120 of 396\n",
      "Processing batch 121 of 396\n",
      "Processing batch 122 of 396\n",
      "Processing batch 123 of 396\n",
      "Processing batch 124 of 396\n",
      "Processing batch 125 of 396\n",
      "Processing batch 126 of 396\n",
      "Processing batch 127 of 396\n",
      "Processing batch 128 of 396\n",
      "Processing batch 129 of 396\n",
      "Processing batch 130 of 396\n",
      "Processing batch 131 of 396\n",
      "Processing batch 132 of 396\n",
      "Processing batch 133 of 396\n",
      "Processing batch 134 of 396\n",
      "Processing batch 135 of 396\n",
      "Processing batch 136 of 396\n",
      "Processing batch 137 of 396\n",
      "Processing batch 138 of 396\n",
      "Processing batch 139 of 396\n",
      "Processing batch 140 of 396\n",
      "Processing batch 141 of 396\n",
      "Processing batch 142 of 396\n",
      "Processing batch 143 of 396\n",
      "Processing batch 144 of 396\n",
      "Processing batch 145 of 396\n",
      "Processing batch 146 of 396\n",
      "Processing batch 147 of 396\n",
      "Processing batch 148 of 396\n",
      "Processing batch 149 of 396\n",
      "Processing batch 150 of 396\n",
      "Processing batch 151 of 396\n",
      "Processing batch 152 of 396\n",
      "Processing batch 153 of 396\n",
      "Processing batch 154 of 396\n",
      "Processing batch 155 of 396\n",
      "Processing batch 156 of 396\n",
      "Processing batch 157 of 396\n",
      "Processing batch 158 of 396\n",
      "Processing batch 159 of 396\n",
      "Processing batch 160 of 396\n",
      "Processing batch 161 of 396\n",
      "Processing batch 162 of 396\n",
      "Processing batch 163 of 396\n",
      "Processing batch 164 of 396\n",
      "Processing batch 165 of 396\n",
      "Processing batch 166 of 396\n",
      "Processing batch 167 of 396\n",
      "Processing batch 168 of 396\n",
      "Processing batch 169 of 396\n",
      "Processing batch 170 of 396\n",
      "Processing batch 171 of 396\n",
      "Processing batch 172 of 396\n",
      "Processing batch 173 of 396\n",
      "Processing batch 174 of 396\n",
      "Processing batch 175 of 396\n",
      "Processing batch 176 of 396\n",
      "Processing batch 177 of 396\n",
      "Processing batch 178 of 396\n",
      "Processing batch 179 of 396\n",
      "Processing batch 180 of 396\n",
      "Processing batch 181 of 396\n",
      "Processing batch 182 of 396\n",
      "Processing batch 183 of 396\n",
      "Processing batch 184 of 396\n",
      "Processing batch 185 of 396\n",
      "Processing batch 186 of 396\n",
      "Processing batch 187 of 396\n",
      "Processing batch 188 of 396\n",
      "Processing batch 189 of 396\n",
      "Processing batch 190 of 396\n",
      "Processing batch 191 of 396\n",
      "Processing batch 192 of 396\n",
      "Processing batch 193 of 396\n",
      "Processing batch 194 of 396\n",
      "Processing batch 195 of 396\n",
      "Processing batch 196 of 396\n",
      "Processing batch 197 of 396\n",
      "Processing batch 198 of 396\n",
      "Processing batch 199 of 396\n",
      "Processing batch 200 of 396\n",
      "Processing batch 201 of 396\n",
      "Processing batch 202 of 396\n",
      "Processing batch 203 of 396\n",
      "Processing batch 204 of 396\n",
      "Processing batch 205 of 396\n",
      "Processing batch 206 of 396\n",
      "Processing batch 207 of 396\n",
      "Processing batch 208 of 396\n",
      "Processing batch 209 of 396\n",
      "Processing batch 210 of 396\n",
      "Processing batch 211 of 396\n",
      "Processing batch 212 of 396\n",
      "Processing batch 213 of 396\n",
      "Processing batch 214 of 396\n",
      "Processing batch 215 of 396\n",
      "Processing batch 216 of 396\n",
      "Processing batch 217 of 396\n",
      "Processing batch 218 of 396\n",
      "Processing batch 219 of 396\n",
      "Processing batch 220 of 396\n",
      "Processing batch 221 of 396\n",
      "Processing batch 222 of 396\n",
      "Processing batch 223 of 396\n",
      "Processing batch 224 of 396\n",
      "Processing batch 225 of 396\n",
      "Processing batch 226 of 396\n",
      "Processing batch 227 of 396\n",
      "Processing batch 228 of 396\n",
      "Processing batch 229 of 396\n",
      "Processing batch 230 of 396\n",
      "Processing batch 231 of 396\n",
      "Processing batch 232 of 396\n",
      "Processing batch 233 of 396\n",
      "Processing batch 234 of 396\n",
      "Processing batch 235 of 396\n",
      "Processing batch 236 of 396\n",
      "Processing batch 237 of 396\n",
      "Processing batch 238 of 396\n",
      "Processing batch 239 of 396\n",
      "Processing batch 240 of 396\n",
      "Processing batch 241 of 396\n",
      "Processing batch 242 of 396\n",
      "Processing batch 243 of 396\n",
      "Processing batch 244 of 396\n",
      "Processing batch 245 of 396\n",
      "Processing batch 246 of 396\n",
      "Processing batch 247 of 396\n",
      "Processing batch 248 of 396\n",
      "Processing batch 249 of 396\n",
      "Processing batch 250 of 396\n",
      "Processing batch 251 of 396\n",
      "Processing batch 252 of 396\n",
      "Processing batch 253 of 396\n",
      "Processing batch 254 of 396\n",
      "Processing batch 255 of 396\n",
      "Processing batch 256 of 396\n",
      "Processing batch 257 of 396\n",
      "Processing batch 258 of 396\n",
      "Processing batch 259 of 396\n",
      "Processing batch 260 of 396\n",
      "Processing batch 261 of 396\n",
      "Processing batch 262 of 396\n",
      "Processing batch 263 of 396\n",
      "Processing batch 264 of 396\n",
      "Processing batch 265 of 396\n",
      "Processing batch 266 of 396\n",
      "Processing batch 267 of 396\n",
      "Processing batch 268 of 396\n",
      "Processing batch 269 of 396\n",
      "Processing batch 270 of 396\n",
      "Processing batch 271 of 396\n",
      "Processing batch 272 of 396\n",
      "Processing batch 273 of 396\n",
      "Processing batch 274 of 396\n",
      "Processing batch 275 of 396\n",
      "Processing batch 276 of 396\n",
      "Processing batch 277 of 396\n",
      "Processing batch 278 of 396\n",
      "Processing batch 279 of 396\n",
      "Processing batch 280 of 396\n",
      "Processing batch 281 of 396\n",
      "Processing batch 282 of 396\n",
      "Processing batch 283 of 396\n",
      "Processing batch 284 of 396\n",
      "Processing batch 285 of 396\n",
      "Processing batch 286 of 396\n",
      "Processing batch 287 of 396\n",
      "Processing batch 288 of 396\n",
      "Processing batch 289 of 396\n",
      "Processing batch 290 of 396\n",
      "Processing batch 291 of 396\n",
      "Processing batch 292 of 396\n",
      "Processing batch 293 of 396\n",
      "Processing batch 294 of 396\n",
      "Processing batch 295 of 396\n",
      "Processing batch 296 of 396\n",
      "Processing batch 297 of 396\n",
      "Processing batch 298 of 396\n",
      "Processing batch 299 of 396\n",
      "Processing batch 300 of 396\n",
      "Processing batch 301 of 396\n",
      "Processing batch 302 of 396\n",
      "Processing batch 303 of 396\n",
      "Processing batch 304 of 396\n",
      "Processing batch 305 of 396\n",
      "Processing batch 306 of 396\n",
      "Processing batch 307 of 396\n",
      "Processing batch 308 of 396\n",
      "Processing batch 309 of 396\n",
      "Processing batch 310 of 396\n",
      "Processing batch 311 of 396\n",
      "Processing batch 312 of 396\n",
      "Processing batch 313 of 396\n",
      "Processing batch 314 of 396\n",
      "Processing batch 315 of 396\n",
      "Processing batch 316 of 396\n",
      "Processing batch 317 of 396\n",
      "Processing batch 318 of 396\n",
      "Processing batch 319 of 396\n",
      "Processing batch 320 of 396\n",
      "Processing batch 321 of 396\n",
      "Processing batch 322 of 396\n",
      "Processing batch 323 of 396\n",
      "Processing batch 324 of 396\n",
      "Processing batch 325 of 396\n",
      "Processing batch 326 of 396\n",
      "Processing batch 327 of 396\n",
      "Processing batch 328 of 396\n",
      "Processing batch 329 of 396\n",
      "Processing batch 330 of 396\n",
      "Processing batch 331 of 396\n",
      "Processing batch 332 of 396\n",
      "Processing batch 333 of 396\n",
      "Processing batch 334 of 396\n",
      "Processing batch 335 of 396\n",
      "Processing batch 336 of 396\n",
      "Processing batch 337 of 396\n",
      "Processing batch 338 of 396\n",
      "Processing batch 339 of 396\n",
      "Processing batch 340 of 396\n",
      "Processing batch 341 of 396\n",
      "Processing batch 342 of 396\n",
      "Processing batch 343 of 396\n",
      "Processing batch 344 of 396\n",
      "Processing batch 345 of 396\n",
      "Processing batch 346 of 396\n",
      "Processing batch 347 of 396\n",
      "Processing batch 348 of 396\n",
      "Processing batch 349 of 396\n",
      "Processing batch 350 of 396\n",
      "Processing batch 351 of 396\n",
      "Processing batch 352 of 396\n",
      "Processing batch 353 of 396\n",
      "Processing batch 354 of 396\n",
      "Processing batch 355 of 396\n",
      "Processing batch 356 of 396\n",
      "Processing batch 357 of 396\n",
      "Processing batch 358 of 396\n",
      "Processing batch 359 of 396\n",
      "Processing batch 360 of 396\n",
      "Processing batch 361 of 396\n",
      "Processing batch 362 of 396\n",
      "Processing batch 363 of 396\n",
      "Processing batch 364 of 396\n",
      "Processing batch 365 of 396\n",
      "Processing batch 366 of 396\n",
      "Processing batch 367 of 396\n",
      "Processing batch 368 of 396\n",
      "Processing batch 369 of 396\n",
      "Processing batch 370 of 396\n",
      "Processing batch 371 of 396\n",
      "Processing batch 372 of 396\n",
      "Processing batch 373 of 396\n",
      "Processing batch 374 of 396\n",
      "Processing batch 375 of 396\n",
      "Processing batch 376 of 396\n",
      "Processing batch 377 of 396\n",
      "Processing batch 378 of 396\n",
      "Processing batch 379 of 396\n",
      "Processing batch 380 of 396\n",
      "Processing batch 381 of 396\n",
      "Processing batch 382 of 396\n",
      "Processing batch 383 of 396\n",
      "Processing batch 384 of 396\n",
      "Processing batch 385 of 396\n",
      "Processing batch 386 of 396\n",
      "Processing batch 387 of 396\n",
      "Processing batch 388 of 396\n",
      "Processing batch 389 of 396\n",
      "Processing batch 390 of 396\n",
      "Processing batch 391 of 396\n",
      "Processing batch 392 of 396\n",
      "Processing batch 393 of 396\n",
      "Processing batch 394 of 396\n",
      "Processing batch 395 of 396\n",
      "Processing batch 396 of 396\n"
     ]
    }
   ],
   "source": [
    "seq_embed,seq_lable=data_loader.extract_embeddings(df['label'],df['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36628/111880977.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  batch_data, batch_labels = torch.FloatTensor(seq_embed), torch.LongTensor(seq_lable)\n"
     ]
    }
   ],
   "source": [
    "batch_data, batch_labels = torch.FloatTensor(seq_embed), torch.LongTensor(seq_lable)\n",
    "batch_data, batch_labels = batch_data.cuda(), batch_labels.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layer1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "  (layer2): Linear(in_features=640, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model.net as net\n",
    "import os\n",
    "model = net.Net(params).cuda() if params.cuda else net.Net(params)\n",
    "utils.load_checkpoint('./experiments/esm_650M/best.pth.tar', model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch = model(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Accuracy: 0.9993181043300375\n",
      "Class 1 Accuracy: 0.9980815347721822\n",
      "Class 2 Accuracy: 0.9994890137966275\n",
      "Class 3 Accuracy: 1.0\n",
      "Class 4 Accuracy: 0.9939903846153846\n",
      "Class 5 Accuracy: 0.9953703703703703\n",
      "Class 6 Accuracy: 0.9987468671679198\n",
      "Class 7 Accuracy: 0.9986631016042781\n",
      "Class 8 Accuracy: 1.0\n",
      "Class 9 Accuracy: 1.0\n",
      "Class 10 Accuracy: 0.9857142857142858\n",
      "Class 11 Accuracy: 0.9365079365079365\n",
      "Overall Accuracy: 0.9977622745820719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_classes=12\n",
    "batch_labels=batch_labels.cpu()\n",
    "y_val_pred = output_batch.cpu().argmax(dim=1).numpy()\n",
    "# 计算每个类别的准确率\n",
    "class_accuracies = []\n",
    "for class_label in range(num_classes):\n",
    "    class_indices = (y_val_pred == class_label)\n",
    "    class_accuracy = accuracy_score(batch_labels[class_indices], y_val_pred[class_indices])\n",
    "    class_accuracies.append(class_accuracy)\n",
    "    print(f'Class {class_label} Accuracy: {class_accuracy}')\n",
    "\n",
    "# 计算总体准确率\n",
    "overall_accuracy = accuracy_score(batch_labels, y_val_pred)\n",
    "print(f'Overall Accuracy: {overall_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  1,  1,  1,  1,  1,  5,  1,  1,  3,  3,  5,  5,  5,  5,  3,  3,\n",
       "         3,  5,  5,  3,  4,  3,  5,  3,  3,  6,  4,  4,  5,  4,  4,  4,  5,  4,\n",
       "         4,  3,  0,  4,  4,  6,  1,  6, 10,  6,  6,  0,  0,  0,  6,  0,  0,  0,\n",
       "         0,  6, 11,  6,  6,  6, 10, 10,  0,  0,  7,  7,  7,  7,  7,  7, 12,  7,\n",
       "         7, 10, 10, 10, 12,  7, 12, 10, 11, 12,  7, 12, 12, 12,  2, 12, 12,  9,\n",
       "        12,  9,  9,  2,  9,  9,  9,  2,  8,  2,  2,  8,  2,  9,  9,  9, 11,  8,\n",
       "         2,  2,  9,  2, 11, 11,  2,  8, 11, 11, 11, 11, 11,  8, 10, 10, 10,  8,\n",
       "         8,  8,  8,  8], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cas2, 0.00%,99.99%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas2, 0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas2, 0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas2, 0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas2, 0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas2, 0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas2, 0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas6, 0.07%,0.00%,0.00%,0.00%,0.00%,99.93%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas2, 0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas2, 0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas4, 0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas4, 0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas6, 0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas6, 0.00%,0.00%,0.00%,0.01%,0.04%,99.93%,0.00%,0.01%,0.00%,0.00%,0.00%,0.00%\n",
      "cas6, 0.01%,0.00%,0.00%,0.00%,0.01%,99.98%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas6, 0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas4, 0.00%,0.00%,0.00%,99.99%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas4, 0.01%,0.00%,0.00%,99.98%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas4, 0.01%,0.00%,0.00%,99.99%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas6, 0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas6, 0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas4, 0.00%,0.00%,0.00%,99.99%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas5, 0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas4, 0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas6, 0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas4, 0.00%,0.00%,0.00%,99.99%,0.01%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas4, 0.00%,0.00%,0.00%,99.99%,0.01%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas7, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas5, 0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas5, 0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas6, 0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas5, 0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas5, 0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas5, 0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas6, 0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas5, 0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas5, 0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas4, 0.14%,0.01%,0.00%,99.80%,0.01%,0.02%,0.00%,0.01%,0.00%,0.00%,0.00%,0.00%\n",
      "cas1, 100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas5, 0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas5, 0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas7, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas2, 0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas7, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas11, 0.06%,0.01%,0.01%,0.00%,0.00%,0.04%,0.00%,0.00%,0.00%,0.00%,99.88%,0.00%\n",
      "cas7, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas7, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas1, 100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas1, 99.99%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas1, 100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas7, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas1, 100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas1, 100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas1, 100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas1, 100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas7, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas12, 0.05%,0.00%,0.00%,0.00%,0.03%,0.01%,0.00%,0.80%,0.03%,0.07%,0.83%,98.18%\n",
      "cas7, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas7, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas7, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas11, 0.02%,0.26%,0.00%,0.01%,0.01%,0.58%,0.00%,0.03%,0.04%,0.00%,99.04%,0.01%\n",
      "cas11, 2.91%,14.38%,0.22%,0.97%,0.10%,0.45%,0.04%,0.13%,0.91%,0.07%,79.82%,0.01%\n",
      "cas1, 99.93%,0.03%,0.01%,0.03%,0.00%,0.00%,0.00%,0.01%,0.00%,0.00%,0.00%,0.00%\n",
      "cas1, 99.83%,0.00%,0.00%,0.13%,0.02%,0.00%,0.00%,0.02%,0.00%,0.00%,0.00%,0.00%\n",
      "cas8, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas8, 0.00%,0.00%,0.00%,0.00%,0.01%,0.00%,0.01%,99.99%,0.00%,0.00%,0.00%,0.00%\n",
      "cas8, 0.00%,0.00%,0.00%,0.00%,0.02%,0.00%,0.01%,99.96%,0.00%,0.00%,0.00%,0.00%\n",
      "cas8, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas8, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas8, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas13, 0.44%,0.72%,27.64%,0.30%,69.89%,0.55%,0.38%,0.06%,0.00%,0.01%,0.00%,0.00%\n",
      "cas8, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas8, 0.00%,0.00%,0.00%,0.00%,0.01%,0.00%,0.01%,99.98%,0.00%,0.00%,0.00%,0.00%\n",
      "cas11, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.01%,99.98%,0.00%\n",
      "cas11, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,99.99%,0.00%\n",
      "cas11, 0.00%,0.00%,0.00%,0.00%,0.00%,0.01%,0.00%,0.00%,0.00%,0.00%,99.99%,0.00%\n",
      "cas13, 2.31%,5.18%,33.45%,0.91%,48.38%,9.11%,0.37%,0.22%,0.01%,0.04%,0.02%,0.00%\n",
      "cas8, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas13, 2.24%,3.35%,31.08%,0.61%,56.30%,5.42%,0.72%,0.14%,0.01%,0.09%,0.03%,0.00%\n",
      "cas11, 0.00%,0.00%,0.01%,0.00%,0.00%,0.01%,0.00%,0.00%,0.00%,0.00%,99.98%,0.00%\n",
      "cas12, 0.23%,0.00%,0.02%,0.05%,5.26%,0.68%,0.00%,0.41%,2.12%,0.11%,0.53%,90.59%\n",
      "cas13, 36.11%,0.58%,24.26%,1.83%,31.21%,0.16%,2.84%,2.92%,0.05%,0.03%,0.01%,0.00%\n",
      "cas8, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,99.84%,0.00%,0.14%,0.00%,0.00%\n",
      "cas13, 57.46%,1.05%,22.62%,4.98%,9.85%,0.27%,1.39%,2.31%,0.03%,0.02%,0.02%,0.00%\n",
      "cas13, 37.60%,0.37%,22.73%,4.50%,27.20%,0.14%,6.03%,1.36%,0.04%,0.03%,0.01%,0.00%\n",
      "cas13, 33.88%,0.51%,30.52%,5.00%,26.09%,0.31%,2.62%,1.01%,0.03%,0.03%,0.02%,0.00%\n",
      "cas3, 0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas13, 21.98%,0.07%,8.63%,1.42%,62.60%,0.48%,3.72%,1.08%,0.02%,0.00%,0.00%,0.00%\n",
      "cas13, 30.45%,0.12%,9.55%,2.34%,51.45%,1.28%,3.42%,1.35%,0.04%,0.00%,0.00%,0.00%\n",
      "cas10, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%\n",
      "cas13, 10.93%,6.71%,42.94%,17.80%,10.39%,6.61%,0.18%,4.20%,0.08%,0.04%,0.12%,0.00%\n",
      "cas10, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%\n",
      "cas10, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%\n",
      "cas3, 0.00%,0.00%,99.99%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas10, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%\n",
      "cas10, 0.01%,0.00%,0.00%,0.00%,0.03%,0.00%,0.03%,3.34%,0.01%,96.54%,0.03%,0.01%\n",
      "cas10, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.01%,0.00%,0.00%,99.99%,0.00%,0.00%\n",
      "cas3, 0.00%,0.00%,99.99%,0.00%,0.01%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas9, 0.02%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,99.97%,0.00%,0.00%,0.00%\n",
      "cas3, 0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas3, 0.00%,0.00%,99.98%,0.00%,0.01%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas9, 0.02%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,99.98%,0.00%,0.00%,0.00%\n",
      "cas3, 0.00%,0.00%,100.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas10, 0.03%,0.00%,0.18%,0.00%,0.04%,0.00%,0.01%,0.74%,0.01%,98.97%,0.01%,0.01%\n",
      "cas10, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%\n",
      "cas10, 0.00%,0.00%,0.01%,0.00%,0.00%,0.00%,0.01%,0.00%,0.00%,99.98%,0.00%,0.00%\n",
      "cas12, 0.02%,0.00%,0.00%,0.00%,0.17%,0.00%,0.01%,0.05%,0.54%,0.02%,0.70%,98.50%\n",
      "cas9, 0.04%,0.00%,0.00%,0.00%,0.00%,0.00%,0.01%,0.00%,99.94%,0.00%,0.01%,0.00%\n",
      "cas3, 0.00%,0.00%,99.99%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas3, 0.01%,0.00%,99.99%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas10, 0.00%,0.00%,0.01%,0.00%,0.00%,0.00%,0.01%,0.02%,0.00%,99.95%,0.00%,0.00%\n",
      "cas3, 0.01%,0.00%,99.98%,0.00%,0.01%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas12, 0.00%,0.00%,0.00%,0.00%,0.01%,0.00%,0.00%,0.00%,0.01%,0.01%,0.05%,99.93%\n",
      "cas12, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.01%,0.04%,0.00%,0.16%,99.78%\n",
      "cas3, 0.01%,0.00%,99.99%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%\n",
      "cas9, 0.01%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,99.99%,0.00%,0.00%,0.00%\n",
      "cas12, 0.01%,0.00%,0.00%,0.00%,0.05%,0.00%,0.00%,0.04%,0.04%,0.02%,0.21%,99.63%\n",
      "cas12, 0.00%,0.00%,0.00%,0.00%,0.01%,0.00%,0.00%,0.00%,0.01%,0.03%,0.10%,99.85%\n",
      "cas12, 0.02%,0.00%,0.00%,0.00%,0.15%,0.00%,0.00%,0.03%,1.29%,0.09%,0.12%,98.30%\n",
      "cas12, 0.00%,0.00%,0.00%,0.00%,0.07%,0.00%,0.00%,0.00%,0.16%,0.07%,0.15%,99.54%\n",
      "cas12, 0.01%,0.00%,0.00%,0.00%,0.05%,0.00%,0.00%,0.00%,0.12%,0.04%,0.04%,99.73%\n",
      "cas9, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%\n",
      "cas11, 0.00%,0.00%,0.02%,0.00%,0.00%,0.00%,0.01%,0.01%,0.06%,0.02%,99.87%,0.00%\n",
      "cas11, 0.00%,0.00%,0.01%,0.00%,0.00%,0.00%,0.01%,0.01%,0.11%,0.01%,99.84%,0.00%\n",
      "cas11, 0.01%,0.00%,0.02%,0.00%,0.00%,0.00%,0.00%,0.00%,0.06%,0.00%,99.90%,0.00%\n",
      "cas9, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%\n",
      "cas9, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,99.99%,0.00%,0.00%,0.00%\n",
      "cas9, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,100.00%,0.00%,0.00%,0.00%\n",
      "cas9, 0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,0.00%,99.99%,0.00%,0.00%,0.00%\n",
      "cas9, 0.02%,0.01%,0.00%,0.00%,0.02%,0.01%,0.11%,0.03%,99.04%,0.36%,0.36%,0.03%\n"
     ]
    }
   ],
   "source": [
    "for index in range(0,len(output_batch)):\n",
    "    softmax_output = F.softmax(output_batch[index], dim=0)\n",
    "    #if batch_labels[index].item() == 0:\n",
    "        # print(str(batch_labels[index].item()+1),\" | \".join([f\"cas {i+1}: {probability.item():.4f}\" for i, probability in enumerate(softmax_output)]))\n",
    "    all_data=[\"{:.2%}\".format(probability) for i, probability in enumerate(softmax_output)]\n",
    "    print(\"cas\"+str(batch_labels[index].item()+1)+',',','.join(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, index = torch.max(output_batch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = torch.nn.functional.softmax(output_batch, dim=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 12 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/data/tony_project/cas_classification/nocas_test.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzj_fyd_hujie/data/tony_project/cas_classification/nocas_test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m _, indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msort(output_batch, descending\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bzj_fyd_hujie/data/tony_project/cas_classification/nocas_test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m [(batch_labels[idx], percentage[idx]\u001b[39m.\u001b[39mitem()) \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices[\u001b[39m0\u001b[39m][:\u001b[39m5\u001b[39m]]\n",
      "\u001b[1;32m/data/tony_project/cas_classification/nocas_test.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bzj_fyd_hujie/data/tony_project/cas_classification/nocas_test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m _, indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msort(output_batch, descending\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bzj_fyd_hujie/data/tony_project/cas_classification/nocas_test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m [(batch_labels[idx], percentage[idx]\u001b[39m.\u001b[39;49mitem()) \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices[\u001b[39m0\u001b[39m][:\u001b[39m5\u001b[39m]]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 12 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "_, indices = torch.sort(output_batch, descending=True)\n",
    "[(batch_labels[idx], percentage[idx].item()) for idx in indices[0][:5]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
